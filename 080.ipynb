{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"figs/LogoUFSCar.jpg\" alt=\"Logo UFScar\" width=\"110\" align=\"left\"/>  <br/> <center>Universidade Federal de São Carlos (UFSCar)<br/><font size=\"4\"> Departamento de Computação, campus Sorocaba</center></font>\n",
    "</p>\n",
    "\n",
    "<font size=\"4\"><center><b>Disciplina: Aprendizado de Máquina</b></center></font>\n",
    "  \n",
    "<font size=\"3\"><center>Prof. Dr. Tiago A. Almeida</center></font>\n",
    "\n",
    "## <center>Projeto Final</center>\n",
    "\n",
    "**Aluno**: Eduardo Garcia do Nascimento\n",
    "\n",
    "**RA/CPF**: 22008732800\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Análise exploratória\n",
    "\n",
    "Nesta seção, deve ser feita a leitura da base de dados e todas as análises necessárias para entendê-la melhor, tais como:\n",
    "* Significado de cada atributo\n",
    "* Medidas descritivas\n",
    "* Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>D0000</th>\n",
       "      <th>D0001</th>\n",
       "      <th>D0002</th>\n",
       "      <th>D0003</th>\n",
       "      <th>D0004</th>\n",
       "      <th>D0005</th>\n",
       "      <th>D0006</th>\n",
       "      <th>D0007</th>\n",
       "      <th>D0008</th>\n",
       "      <th>...</th>\n",
       "      <th>D0138</th>\n",
       "      <th>D0139</th>\n",
       "      <th>D0140</th>\n",
       "      <th>D0141</th>\n",
       "      <th>D0142</th>\n",
       "      <th>D0143</th>\n",
       "      <th>D0144</th>\n",
       "      <th>D0145</th>\n",
       "      <th>D0146</th>\n",
       "      <th>D0147</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.384615</td>\n",
       "      <td>8.384615</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2.180207</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>-16.015176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447179</td>\n",
       "      <td>-14.656926</td>\n",
       "      <td>0.018882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.723971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>34.294117</td>\n",
       "      <td>9.222222</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.867641</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>-16.552813</td>\n",
       "      <td>1.781575</td>\n",
       "      <td>1.377964</td>\n",
       "      <td>-16.016694</td>\n",
       "      <td>0.025232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.305677</td>\n",
       "      <td>1.305677</td>\n",
       "      <td>18.705883</td>\n",
       "      <td>18.705883</td>\n",
       "      <td>15.863636</td>\n",
       "      <td>15.863636</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2.627386</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-16.548139</td>\n",
       "      <td>0.344645</td>\n",
       "      <td>0.108658</td>\n",
       "      <td>-15.307439</td>\n",
       "      <td>-0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.141328</td>\n",
       "      <td>9.170616</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.595238</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>3.886364</td>\n",
       "      <td>48.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.216561</td>\n",
       "      <td>0.829762</td>\n",
       "      <td>-14.697490</td>\n",
       "      <td>0.303174</td>\n",
       "      <td>0.401714</td>\n",
       "      <td>-14.083293</td>\n",
       "      <td>0.005164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.113582</td>\n",
       "      <td>0.113582</td>\n",
       "      <td>1137.434814</td>\n",
       "      <td>1137.434814</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.135548</td>\n",
       "      <td>0.554348</td>\n",
       "      <td>-9.595501</td>\n",
       "      <td>0.589175</td>\n",
       "      <td>0.100116</td>\n",
       "      <td>-13.572599</td>\n",
       "      <td>-0.000632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234.380325</td>\n",
       "      <td>49.266010</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>10.583333</td>\n",
       "      <td>2.570318</td>\n",
       "      <td>8.292994</td>\n",
       "      <td>1287.0</td>\n",
       "      <td>628.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.914</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>5.476159</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>-12.069193</td>\n",
       "      <td>1.505100</td>\n",
       "      <td>0.357536</td>\n",
       "      <td>-10.992013</td>\n",
       "      <td>-0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.548214</td>\n",
       "      <td>52.099346</td>\n",
       "      <td>327.666656</td>\n",
       "      <td>162.520004</td>\n",
       "      <td>10.001031</td>\n",
       "      <td>9.875256</td>\n",
       "      <td>970.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.440</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>5.852683</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>-12.741077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081810</td>\n",
       "      <td>-11.460218</td>\n",
       "      <td>0.000516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.247425</td>\n",
       "      <td>32.247425</td>\n",
       "      <td>92.830185</td>\n",
       "      <td>92.830185</td>\n",
       "      <td>14.630458</td>\n",
       "      <td>14.630458</td>\n",
       "      <td>939.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.946</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>5.818093</td>\n",
       "      <td>0.064151</td>\n",
       "      <td>-11.983040</td>\n",
       "      <td>1.424396</td>\n",
       "      <td>1.454859</td>\n",
       "      <td>-12.039741</td>\n",
       "      <td>-0.053146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.368022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-17.207213</td>\n",
       "      <td>0.434202</td>\n",
       "      <td>1.788514</td>\n",
       "      <td>-17.173907</td>\n",
       "      <td>-0.424863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.535825</td>\n",
       "      <td>1.535825</td>\n",
       "      <td>24.900000</td>\n",
       "      <td>24.900000</td>\n",
       "      <td>29.771931</td>\n",
       "      <td>29.771931</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.436594</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>-15.812102</td>\n",
       "      <td>0.957110</td>\n",
       "      <td>0.443102</td>\n",
       "      <td>-14.505732</td>\n",
       "      <td>0.004381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  D0000       D0001      D0002        D0003        D0004      D0005  \\\n",
       "0   0    1.0    1.400000   1.400000     9.000000     9.000000   8.384615   \n",
       "1   1    0.0    0.723971   1.000000     9.000000     8.900000  34.294117   \n",
       "2   2    1.0    1.305677   1.305677    18.705883    18.705883  15.863636   \n",
       "3   3    0.0    5.141328   9.170616     1.000000     2.595238   7.166667   \n",
       "4   4    1.0    0.113582   0.113582  1137.434814  1137.434814   6.600000   \n",
       "5   5    0.0  234.380325  49.266010   628.000000    10.583333   2.570318   \n",
       "6   6    0.0   51.548214  52.099346   327.666656   162.520004  10.001031   \n",
       "7   7    1.0   32.247425  32.247425    92.830185    92.830185  14.630458   \n",
       "8   8    1.0    0.526882   0.526882     1.500000     1.500000   9.600000   \n",
       "9   9    1.0    1.535825   1.535825    24.900000    24.900000  29.771931   \n",
       "\n",
       "       D0006   D0007  D0008  ...  D0138  D0139    D0140     D0141     D0142  \\\n",
       "0   8.384615    13.0   13.0  ...  0.024  0.040  0.00001  2.180207  0.850000   \n",
       "1   9.222222    17.0    9.0  ...  0.020  0.058  0.00001  1.867641  0.850000   \n",
       "2  15.863636    22.0   22.0  ...  0.046  0.028  0.00001  2.627386  0.800000   \n",
       "3   3.886364    48.0   44.0  ...  0.226  0.030  0.00001  3.216561  0.829762   \n",
       "4   6.600000    40.0   40.0  ...  0.084  0.050  0.00001  3.135548  0.554348   \n",
       "5   8.292994  1287.0  628.0  ...  3.914  0.038  0.00001  5.476159  0.566667   \n",
       "6   9.875256   970.0  978.0  ...  2.440  0.034  0.00001  5.852683  0.748000   \n",
       "7  14.630458   939.0  939.0  ...  1.946  0.046  0.00001  5.818093  0.064151   \n",
       "8   9.600000     5.0    5.0  ...  0.054  0.056  0.00001  1.368022  0.000000   \n",
       "9  29.771931    57.0   57.0  ...  0.090  0.034  0.00001  3.436594  0.850000   \n",
       "\n",
       "       D0143     D0144     D0145      D0146     D0147  \n",
       "0 -16.015176  0.000000  0.447179 -14.656926  0.018882  \n",
       "1 -16.552813  1.781575  1.377964 -16.016694  0.025232  \n",
       "2 -16.548139  0.344645  0.108658 -15.307439 -0.000148  \n",
       "3 -14.697490  0.303174  0.401714 -14.083293  0.005164  \n",
       "4  -9.595501  0.589175  0.100116 -13.572599 -0.000632  \n",
       "5 -12.069193  1.505100  0.357536 -10.992013 -0.146300  \n",
       "6 -12.741077  0.000000  0.081810 -11.460218  0.000516  \n",
       "7 -11.983040  1.424396  1.454859 -12.039741 -0.053146  \n",
       "8 -17.207213  0.434202  1.788514 -17.173907 -0.424863  \n",
       "9 -15.812102  0.957110  0.443102 -14.505732  0.004381  \n",
       "\n",
       "[10 rows x 309 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Caminho dos arquivos\n",
    "FILES_DIRECTORY = \"data\"\n",
    "\n",
    "import numpy as np  # importa a biblioteca usada para trabalhar com vetores e matrizes\n",
    "import pandas as pd # importa a biblioteca usada para trabalhar com dataframes (dados em formato de tabela) e análise de dados\n",
    "import os # importa a biblioteca para tarefas relacionadas ao sistema operacional\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "        \n",
    "        #for i in range(107):#9,22,23,46,47\n",
    "            #col = 'D' + \"{:04d}\".format(i)\n",
    "            #usecols = [col]\n",
    "            \n",
    "            #usecols = [ \"D0023\", \"D0046\", \"D0047\",\"D0048\"] \n",
    "            #usecols = [\"D0004\",\"D0068\"]\n",
    "                       \n",
    "            # importa o arquivo e guarda em um dataframe do Pandas\n",
    "            set1_dataset  = pd.read_csv(os.path.join(FILES_DIRECTORY, 'set1.csv'), sep=',', low_memory=False)\n",
    "            set2_dataset  = pd.read_csv(os.path.join(FILES_DIRECTORY, 'set2.csv'), sep=',', low_memory=False) \n",
    "            set3_dataset  = pd.read_csv(os.path.join(FILES_DIRECTORY, 'set3.csv'), sep=',', low_memory=False) \n",
    "\n",
    "            frames = [ set1_dataset, set2_dataset, set3_dataset]\n",
    "            input_dataset = pd.concat(frames, axis=1)\n",
    "            display(input_dataset.head(10))\n",
    "            \n",
    "            class_dataset = pd.read_csv(os.path.join(FILES_DIRECTORY, 'train.csv'), sep=',', skiprows=range(0, 1), index_col=None, header=None)\n",
    "            test_dataset  = pd.read_csv(os.path.join(FILES_DIRECTORY, 'test.csv'), sep=',', skiprows=range(0, 1), index_col=None, header=None)\n",
    "\n",
    "            print('Dados carregados com sucesso!')\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Pré-processamento\n",
    "\n",
    "Nesta seção, as funções da etapa de pré-processamento dos dados devem ser implementadas e aplicadas (se necessário)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling np arrays with dataframes sources.......................\n",
      "X (60842, 308)\n",
      "y (4564, 2)\n",
      "X_test_index (401, 1)\n",
      "Removing features with no variance....................................\n",
      "Copying a subset of X and y with classes.............................\n",
      "Normalizing scale between 0 and 1..................................\n",
      "(4564, 2)\n",
      "(4564,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEICAYAAABCnX+uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dfXRU93nnv4+GKzRCKQM1bswIIRK8EIMSlMg2PnRPC/FWrh3jsdPUbyQ5S866zrqngfVqI2xOLXKoUZask3STsymtSZ01JvLryDZ2sHNwTja0kApLBFPDug4YGJw1AY8dwUiMpN/+MXOHmTv3de77nedzDgdp5s69j0aj731+z+95ISEEGIZhmPDS4LcBDMMwjD1YyBmGYUIOCznDMEzIYSFnGIYJOSzkDMMwIYeFnGEYJuSwkDORhYiOE9H1Jo4TRLSwxmvU/FqGcQoWcoZhmJDDQs4wDBNyWMiZyENE1xDRPxNRlojeJaLvEVGj4rAbiejXRPRbItpKRA1lr19LRG8S0ftEtJuI5nv8IzCMLizkTD0wCWA9gMsAXAfgswD+s+KYWwF0Afg0gFsArAUAIkoBeADAbQDmAPg/AHZ6YjXDmISFnIk8QogDQoh9QogJIcRxAH8H4I8Uh31TCHFOCHECwHcA3Fl8/C8AbBFCvCmEmADwMIBl7JUzQYKFnIk8RPTviOhFIvoNEX2IghhfpjjsZNnX7wCYW/x6PoDvFsMyWQDnABCApNt2M4xZWMiZeuB/ATgC4EohxO+hECohxTHzyr5uA3C6+PVJAH8hhEiU/YsLIf7JdasZxiQs5Ew98BEAHwIYJaLFAL6qckwPEc0ionkAvgZgoPj4DwBsIKIlAEBEM4noC14YzTBmYSFn6oH/CuAuAL8D8Pe4JNLlDAI4AGAEwC4AjwKAEOI5AN8E8ONiWOYNAH/qgc0MYxriwRIMwzDhhj1yhmGYkMNCzjAME3JYyBmGYUIOCznDMEzImebHRS+77DLR3t7ux6UZhmFCy4EDB34rhJijfNy2kBNRE4CfA5hePN/TQoiH9F7T3t6OoaEhu5dmGIapK4joHbXHnfDIxwGsEkKMEpEE4BdE9LIQYp8D52YYhmEMsC3kopCIPlr8Vir+4+R0hmEYj3Bks5OIYkQ0AuA9AK8KIfarHHMPEQ0R0dCZM2ecuCzDMAwDhzY7hRCTKLT2TAB4joiWCiHeUByzDcA2AOjq6mKPnWEYW+TzeZw6dQpjY2N+m+I4TU1NaG1thSRJpo53NGtFCJElop8BuAGFnhQMwzCucOrUKXzkIx9Be3s7iJTNLMOLEAJnz57FqVOnsGDBAlOvcSJrZQ6AfFHE4wCuR6HJEOMw6eEMtu4+itPZHOYm4ujpXoRUp4NtsR9OAhdHqx9vbAEeyDh3HYZxgLGxsciJOAAQEX7/938fVkLQTnjkVwB4jIhiKMTcnxRCvOjAeZky0sMZbHj2EHL5SQBAJpvDhmcPAYBzYq4m4nqPM4zPRE3EZaz+XE5krfwKQKfd8zD6bN19tCTiMrn8JLbuPuqsV84wTOjgEv2QcDqbs/Q4wzDecuTIEVx33XWYPn06vvWtb2ked+zYMVx77bW48sorcfvtt+PixYu2r+1LiT5jnUSzhPcv5KsebyBCejhT4ZUbxtK1YuEMw9TM7Nmz8bd/+7dIp9O6x33961/H+vXrcccdd+Dee+/Fo48+iq9+VW1olXlYyENAejiD0bEJ1ecmhcCGZw9h6J1zePHgu8jmKsU+k82h56mDAMpi6SziTB3idrLA5Zdfjssvvxy7du3SPEYIgT179uCJJ54AAHz5y19GX1+fbSHn0EoI2Lr7KPJT2qn3ufwkHt93okrEZfJTAn3PH67dgMaW2l/LMAFAThbIZHMQuJQskB72Nhvr7NmzSCQSmDat4EO3trYik7FvA3vkIcCJOHg2ly95JHv1Duz7wPa1GCZoBCVZQG20phOZN+yRh4C5ibgj5+l56iAyvDnK1CFuJQt8//vfx7Jly7Bs2TKcPn3a8PjLLrsM2WwWExOFUOmpU6cwd+5cWzYALOShoKd7EeJSzPZ59MIzDBNltJwhu07Sfffdh5GREYyMjJgSZCLCypUr8fTTTwMAHnvsMdxyyy22bABYyENBqjOJLbd1IJmIgwAk4ub6L8hIscql26hoUj+QY+FMRFFzhuJSDD3dixy7xm9+8xu0trbikUcewebNm9Ha2ooPP/wQAHDjjTeWPPZvfvObeOSRR7Bw4UKcPXsWX/nKV2xfm9RiNm7T1dUleLCEPVb079ENkzQQMCWAZHF3ft3AiOax37l9mbul/wzjAm+++SY+8YlPmD7e9RYXDqP28xHRASFEl/JY3uwMMHofvJ7uRRUl+0DBw9hyW0fpGPn163VEnAD3S/8ZJgCkOpOR/UyzkAcUo94q8gdSS+iVr9dCAKq7+fc/eRDrB0ZC4bkwTL3DQh5QzKRL6XkYaq+3wmQx5JbJ5rB+YARD75zD5lRHzedjGMY9WMgDit10KTPHxaUYpk9r0CwkkhEAduw7AQB47ciZ0MQYGaZeYCEPKHMTcdXNTLPpUlqvjxFhSoiSEAOoCsG8MX0tWqh66srocBMeH98OoOCprxsYwVNDJ7DjP11XeaCJXi7nEcertxzgGwHDOAALeUDR2sw0my61cvEc7Nh3omIKtnIztJzyrBY1Edd6fO/b57AxfagQdrHQjGsG1DdVw5ZZwDBBgPPIA4oydzyZiGuKsJL0cAbPHMhUiDgB+Pxn1GPqqc4kkjUWRrwxfS02j/wh0DfTcjMuOeZfbreyH8b6gRFsTB+qyTaG8YKf/OQnWLRoERYuXIj+/v6q54UQ+Ku/+issXLgQn/zkJ/H66687bgN75AGm1nQptY1OgUJ8Wwu1FYAZtLx3s2SyuVIbXi27H993Ai8efBd9q5ewd84EisnJSdx333149dVX0draiquvvhqrV6/GVVddVTrm5ZdfxltvvYW33noL+/fvx1e/+lXs37/fUTtYyCNILRul5emM8Hgoec9TBzH0zjndAqdsLs/57UztuDSP9pe//CUWLlyIj33sYwCAO+64A4ODgxVCPjg4iC996UsgIixfvhzZbBbvvvsurrjiipqvq4SFPILUulFaWgH0uWSYguNNd2FUNGHp+HY8XsyK0aOUfvnyNTwkmrGGS/NoM5kM5s2bV/q+tbW1yttWOyaTybCQM/rY3SgdFU3qWStaPVps0EJjON50l64tS4uZMkBxVdHEQ6KZYGCmLa1brWvLYSGPIEZVn0Z0x3cGpt2tLPSyoM9NxA1DP5z5wnhFa2srTp48WfperS2tmWPswlkrESXVmcTe3lU41n8T9vausiRkap3ipAbCrGaplEEjo+WlO+29t9CYqVVFUCbBMPXB1VdfjbfeegvHjh3DxYsX8eMf/xirV6+uOGb16tX40Y9+BCEE9u3bh5kzZzoaVgHYI2dUMOPRy90Xy8MeSvRCJrVQipHrHHN9+tNYl6+0Se4dA/BGKeMs06ZNw/e+9z10d3djcnISa9euxZIlS/CDH/wAAHDvvffixhtvxEsvvYSFCxeiubkZP/zhDx23g9vYMjVhpimX00Iuh1eMzts+9oTq43oFUUz4sNTG1qWsFTfhNraM65R77V7F0+UNWK3NWCP8mNHIBISAirVTcIycqRk5Dn+8/yasWd5W9bxb8XO9cI4RTgyyZpigwR454wibUx3omj+7ItziRvzczOvKs1yUCBTi+5zJEg2EEI6n8gUBqyFv9sgZx5D7w8QC8Iclpy2+MX1t1XPcwyUaNDU14ezZs5ZFL+gIIXD27Fk0NZlfubJHzjiK7OUabYTWGue2itY15B7rXfNns2ceUlpbW3Hq1CmcOaPdQyisNDU1obW11fTxLOSM4yjTF9X8JTns4XRmixkq+q0PFv8Bgc5gYKqRJAkLFizw24xAYFvIiWgegB8B+CiAKQDbhBDftXteJtyUd27s/MYreP+C/hQiNzF9s+ASfyakOBEjnwBwvxDiEwCWA7iPiK4yeA1TRzx08xJIseq4OW/QMIwz2PbIhRDvAni3+PXviOhNAEkA/2r33Ew00KoUBYDzg3HMQIBSAvtmIj9tBi5OTKnbxeEXJoA4GiMnonYAnQCquqYT0T0A7gGAtrbqnGMm2mgNyUjjAFKDwVrASRPnIWk9yeEXJoA4trolohYAzwBYJ4T4UPm8EGKbEKJLCNE1Z84cpy7LhBi5zJ9hGHs44pETkYSCiO8QQjzrxDmZ6FMa7RYzPjaIcLtcJijY9sipUFb1KIA3hRCP2DeJqRfkcnmvWuHKCKHdWMss3C6XCRJOeOQrAHwRwCEiGik+9oAQ4iUHzs1EGHkknV4pf0XOdxl2CoqI7OWvL+jdhQYiTCoqCrkpF+MXTmSt/AKA/zXZjCpOLv+dDiWojaRTUmu/lvaxJ1wpNhoVTRBAScSrbjRjKMw85ewWxkO4sjPCKHuGy8t/wPqABSfPJaNMS1TzcoGCl6BWHerlbFGtJlyaqwLObmE8hIU8wpQ2E8uodfnv5LnKKU9LVBtWEZdi+PxnknjtyJmqcn+lsM5qllyrIPWiLwzD1AoLeYTR6r1dS09uJ8+lhZURc0pmNUsY/us/KX3f3rvLMbtk5FCN7J2rdVasoG8mh1gYT2AhjzDyZqLa436eSw+twiEZtbh6XIrhoZuXVByXTMQxmnOnw2ILjWluwlbBIRbGA7jdRYTp6V6EuFSZpG1mEr3b57KD3PM8mYiDUBBstTmcPd2LcPXUY2gfe8KVmDmHWpggwR55hDETqvDjXHYx8trlY4CCvR3Z7ZgZl0AEZC/kkWiWMDz1BS9MZRhPID+ma3R1dYmhoSHPr8swQCHOvjt3p+9e9ahoQnd8J1eEMqYhogNCiC7l4+yRM3XH6WwOS1HIeDEd63aBFhrD3rFbgUEgv2sGpI2nfbGDCT8s5EzdUb5xq5Yb7sfUImnivOfXZKIDb3YydUdP9yLdUmS3eryYJT2cwYr+PVjQuwsr+vdw/xbGEI6RM3WJmTxzr8MuHx/fieUfm4XXT3xQlV6plpnD1B9aMXL2yJm6JGki/33p+HbX0hfVmBQCe98+p1lByzBasJAzdYlReKWcpePbPRHz4013aVaLOllBy0QP3uxk6pJUZxJD75zDjn0nVBtyKVk6vt2TTdDyUE5VaKev+D+X/TMKWMiZSGKm5e7mVAe65s8uHWck6HZ6oNcCd1ZkzMJCzkQOKy13y6tEtRpyAYVWul6mKiYT8UJvc4YxAcfImcih13JXD61+Mt+5fRm+ffsySA3VUXU3YufJRBx7e1c5fl4murBHzkSOWlvumuknU/7cysVz0H1kZ8WxW3cfLVRr2qCnexHSwxmkbJ2FqSdYyJnIodVyt4EIC3p36Tb8kkMtcox9/cAItu4+WjreKJd7/cAI4ICTvuHZQ0jFjI9jGICFnIkgWrNA5TFyRmPqrMTYlZuqM+MSRqfsbYqWQkMs5IxJWMiZyGFmFqjemDqzY+3UBB9AqSEXUMNmaGOLqZzxZZtewQe5vK/thJngwELORJLyMMgCjXJ8q7F05eNqgm+bBzKYq5M9I/OLqS+ipWmskNkyWPwHcI55ncJCzkQe02PqHk4CF0dxTBHjlmd0Ko834zlbyj1vbAFQCA31PHVQ97WcY86Uw+mHTOQxPaZOQwRbaAwEYOXiORWPm5lXaqa8v33sCbSPPYH8lAD6ZiI1eBXeaqx98MXoQ3/AXRPrDPbImcjjxJg6AeCZAxl0zZ9dep3Wpmo5yUQcLb3/D+ibaXgNp3qSt9AYMtkcrk9/GhjUuRlwGCYy1K2QmynhZqKDmdRBI5QbnvL/fc8fRjaXrzpeaqBLXn9ji6rH71YzrmPT7wIZdQW7OFq4wbCgh566FHIr6WUMU44yLl6ed77phcN4/0JB0BNxCX2rl1z6PJUJ5bJNr6gKv5MYing5HFcPPXUp5GbTyxhGiVZc3IrH37d6SVVIxoruMoySyAu5MoSycvEczdQu7vlc5xiEP1Q3SGugPGafyeZAgKlWugyjRWRGvanFvAEYbkYpSXK8nCnixT5KeZjF69FyFfR94M91GUtojXpzRMiJaDuAzwF4Twix1Oh4p4VcGfMGCt5Tk9RQillagQDcvbwNm1MdjtnIMErSwxmsGxjRPcaLYRYAWMhDgtszO/8RwA0OncsyWjHvWkQcKCxzH993Agt6d6GdJ5kzLrHphcOunduqf8af73DjiJALIX4O4JwT56oFo3LmWpH/FjLZHNYNjGDZplf4A884hhlHo5b0xFHRhAXjT6Cz4alSsVH72BO6r+HhzuHGs81OIroHwD0A0NbW5tVlHSWby2PdwAgefO4QpFgDNy1iXOdTF3+IKSFKG/WbR/7Q8DVLx7cjLsXw0M1LMPTOOTy+74Tha/aO3XppJiiA84hj6dij/PkOCZ4JuRBiG4BtQCFG7tV13eD8xUkAnIPO2CMRl3TzyeNSDFtu66j4XI0OG/duKd+wT3Um8dTQKYxPTFmybQYKM0z58x0OQt1rJT2cwZK//onfZiCXn8S6gRGOpTOW6Fu9RHV8HFAQY6WIA0B3fKd+uKWxBXt7V1W8zqqIKzEzJo/xl9DmkSszVbRSt+TOdV7A3gtjhVp6wPR0L8LVzz5WlaGlJvpKLHViVMA1FsHGESEnop0A/hjAZUR0CsBDQohHnTi3FspMFcvtPl2CK0QZK1jtAVOL+MshHDWHxmx6o5lOj4x/OCLkQog7nTiPFYLsIWSyOXx8w0uYFAKzmiUIAd4YZRzDqvj3rV5imK+uh1MVrYx7hDZGHnQPQR4t9v6FPLK5fGnjaN3ACDq/cSmNMT2cwYr+PVjA+eqMS6Q6k1izvK2qn0tciiE/bYbqa84jDoJ2rJ4JFqGNkZvpBR1U3r+Qx4ZnD2HonXN45kCGuzAyrrM51YGu+bOrQjJS52nV42cAOOatiYwNQivkstDZWTL6SS4/iZ37T5oaCsy90+sLt37fTvRkZ4JJaEMrMvJyUSsly63G/U6gFHGZ8vi/nJ2TyV7K610/MIKN6UMeWcl4idrve8OzhzjkxugSWo8cKOzcy1JolGIYhPREs5TH/9X6yAgAO/adqBg7pgZ78uGDe+UztRBqj9xK5kpQ0hONkGKXxoOlhzOafWQE9PtjsGcXTrQ+00HO0mL8JzQeuZp3OTcRd61hll8MT/uPaBkcAwaBFIBUMTKktnLQ++Nmzy6caH2mg56lxfhLKIRca8bm5z+TNNUQKCiYCe9YWTk0ECE9nEHq5WuqJtvsBTA63bz4K2+UP5tYoz7VnQf1uopaNhbncTNGhELItbzLFw++68n1nYqvOx3emRQC6wZGkGpSH56rdl41z07tRik1qYg4wIN6XaaWyk2GCYWQa3mRbk8ilwlLfN0INc8uPZzB/U8e1MygYbyH0wQZq4RCyJ2IhWs1DApKeuLxprtM22JltmNVL41BAC8XwiOyJ84iztji4aT6So3DcJ4RCiFXixtanTyuFgIhAIlmCYA3nr0RZsXZ9krg4ih74owjpIczSGmF2zgM5xmhSD9MdSax5bYOJIvxXasiroVAYbZhTKMndJBweuXAnjhjl/RwBj1PH/TbDAYh8ciBS3HDFf17ag6zqIYkBDAqNeFa8Vhx8o97mO0HrZyvKNvt5ER1ox41mrY2tlR8W2vRERcrhZ+tu48iPykAyW9LmNAIuYydwgi9Tcvz49rCpifARuJantki/29VkGsJpVgdIqCXmdMd34m9vauqntNKCwX0m37V+jomWHCRUnAInZD7UQRkpyG/X5ktVq+rd5MrrzQt96LPj0+opoX2PX9YV5C5WCkaRLEgL6yEIkZeThQKI4zi3ceb7sIb09f6dn0lqc6kasm/VvpnNpdHu05/dS5DjwY93YsgxUj786QIwzHuETqPPNWZxKYXDuP9C8HINKmFpePbDVMInfbklXH3chJxyXD3WM2LNkIrZMJl6NFA/p3++xf+d+nvMRGX0Ld6Ca+sPCZ0Qg4AN33yCtdK8/UyYqzkbxtRa7zcDbK5PGDgpNfqLauFTPTK0HkT1Bucep+5eCkYhC60AgCvHTlT0+uMepZLDYRpMe1URK/j3XJ4JQhFS3a85Uw2VxFiKU8nLR8nBkC197pemIaxDnfGjB6h9Mhr9Q5lL3hWs4SHbl4C4FJPi2QijgsXJxwP2dgRYfnG4ZT3rpeZolf5+tPhDHq6F6HnqYPIT9WWe75uYAQPPncIFy5OljxAZSbMiv49qr3XgYLYXJ/+NDCokRLJFYSm4c3m6BFKIbezW75meRs2pzpK35d/cBf07rJtWxAHVcjoZaboxdAxMIJEXIIUo5qFHEApT18rdm50g9ZcEXEFoSV4szl6hFLIax28nIgXKhc+vuElTAqBBgKmT2vAWH4KcxNxJJol2x651fCL1XzvWjCzKjDq8Gi2QZnZqls1D5DT2dxFjotr/X54szm8hFLIy1t9ZrI5xIhMlZtnc/mKTdIpAeTyUwCKrVt9KNVfOr7d1Q1PsysEpzo8HjLYEC63R46dy7/Pnu5F6Hn6YKFakHEUZRGWkrgUw8rFc7Cifw9vNIeQUAo5UL1bvjF9yHYmi1HYwAvvWYldkffaXqPrKZ8vD7GkOpPoe/6wZ+2J6wm99NFkIo6Vi+fgmQMZrrYNKaHMWlFjc6oDa5a3IUbueNVOph4qCUJWil/k8pO4/8mDpYyJD1jEXUEr/k0A9vauwmtHzmhugDLBJ7QeuRqbUx3YnOpAejiDdQMjjp7bTc9WGfpwK9Sil5ni55CMSSFK3p9WnJwA5KfN0B4/x+hiVITFG6Du42aNRKSEXKZWLyIuxdBAsNUFMcjetV6s3O/CpFx+EpteOIyHbl6i2nv+7uVtkFKn/TMw5BjNAuVqWxcpDt5IoTBQHU0AxoDRdBPSeN0RMY+kkFvxIuJSA3L5KcSIkMtPIhGX0ECTsJJlp5u65wLlG4ZOhXyCMEHp/Qt5bHrhMD7/mSReO3KGN90cxGgWKA99dgGtyUlFWmjMsdz9SAq5URpbjAh3XjsPm1Md2Jg+hB37TpSyXrK5PKQGQlxqcLQ/uVMDnIHKMI9TWS9a/V9aaAxvTF9r2kajMI3RjeH9C3k8cyBTIeblKyxZiGbGJeQnp0q/I+7xYYxeOT0PfXYBE/UNToWuSDgwJYaIbgDwXQAxAP8ghOjXO76rq0sMDQ3Zvq4WaqlW8vIcAHbuP2mYrphMxLG3dxXai0VCemJpxiM383or3nX5NfXObfZGYXRtr1cdynx0KUaAMM4sYkFnAoGBNy6zouk51V7/WhDRASFEl/Jx2x45EcUAfB/AfwBwCsC/ENHzQoh/tXvuWtHyLobeOWc6RVH26I0EzsnQgxsbjmY9aT83O5XYWb1kc3n0PHUQm144jOyFPHuWjD+YrDZ2KnTlRGjlGgD/JoT4NQAQ0Y8B3ALANyEH1JeR9z9pbb5gejiDVIC81Fo4Nv0uqGVk+tFKwGzhlt3ipPyUKFXocj404zW5TR+F2S3iIGWtJAGcLPv+FIBrlQcR0T0A7gGAtrY2By5rjfRwxvKw4a27jxZ2mQOOXlxaK63ebQ/cyT0Bu3BDKMZL4sJk3NvBtFknhFxNKqoUUwixDcA2oBAjd+C6ppFj5kqMxOZ0NmfYp1sPt4qIlOEct8v8AVja8ARq96rd6pLAPVyYwOFgx04nhPwUgHll37cCCFTCr1Z5spHYNNisEjUj4mZj7O1jT5RuDC00ViHcte5Xy+cwY4NXMXQbzRV1cavil2GCgBNC/i8AriSiBQAyAO4A4P/YmzJqTfGxGoqxglp83SiX22r4xCwtNOZ7dafbuPm7ZBhL9H3g+CltC7kQYoKI/hLAbhTSD7cLIQ7btsxB7LRH9bJQxs8+5kEaPefGe57kCkUmCLjUTsKRgiAhxEsAXnLiXG5Qa/9ywF9xdQIh7HvsXuP0e05wLs2LYQxpbFFPP3RxklUkKzuVyNkK9dgidcG4ucIhpwlCyb9Mk9SA9QMj2Lr7KOeUM+7jw9jBuhBymfGJqYrv3RabIImZWZyy2Smv2koa45rlbeiaP7tUCJZoljA6NlExPIRzypkoUjdCrpa54nbYxOnza4msXvikPG1Qb0PzeNNdgZw3ajaNkQB0zZ9dUQi2on9P1ei+8pzyjelDpXYNyrF/7LkzYSIygyWMiEIe8dLx7aqesV4MXNlgS68aNcxZKwKF0Fk5ej225YlScjaLPPZP4JLnLg+7YJigUxdCnh7OqFYthZEwi63bZHP5CvHV6qU9NxHHzv0nVZ+T4ek4TJioi9BK3/OHTU12Z8KPLL7yYG5lF0W5x7aZCVJRmY6THs7gwecOlVr+yp1AN6c6/DWMcYzIC3l6OFN3mSr1TCabQ8/TB5GfLMi3wKWWuIm4BCJgvckxgDPjUulrN8d0uUl6OIP7nzqIybKSWQGUuoCymEeDyAu5l8vjIDWKskOQfg6tjVy9Qk1ZxEvHFv+3ekPPT04hPZypSlsNS/ZLejiD+588qFnVumPfCRbyiBB5IfdyeWy3/aobqG2O1toKwI+fQ2sjl6g6L76WG43RTavcuy8n6B0V5UZxeq0JONwYHSIv5HbK84OI2Z4oeqIWptWBFWq50RjdtNREXCbIMXStRnFMNIm8kGsNlZ0+rSGUsXMzLWvVRDxI4ZKoEOQJ82ZuMjMaYx5YwnhB5IVca+wbAFOZC2FETbCNPE+3eqd7jbK9r9PTkSrepzEAfcUnXOyjUQuGA8gbCH9zK8fHo0LkhRzQnh5ea++VuNSAixMiUq1RoyDiStyYjqT5WpMzGr1CbSUqZ+8kQ5R1w5ijLgqCtOhbvQRxqXJ5KTUQZjVLIACzmiVIipE1cSmGLbd9Em9vubGqNapWPxKne6s4fT6zzbT86BET5L40QSbVmcSW2zqQTMRBKIj3t29fhuP9N2Fv7yoW8YhRFx65Flphl1RnspQ3/P6FfGlocDIRx8rFc7B191GsHxhBolmqOJ/Wcn1WswTAuXi8173D/RwyrfaeOhkGCmNjM7NorUSZ6FHXQg6of9jl1C15WTopBOJSDCsXz8EzBzKlx81aXGQAABPCSURBVJUNmRhvWDq+HQ0EXPex2dj79jlbNzQnN3pX9O8JZ8ji4aTn/bMZZ6nr0IoWaqlbufwkdu4/WVNKl1uCbyWUEwUPs5wpAfzT2+f8NqOCTDaH9QMj2JiuHvQdaLTi+wGL+zPa1L1HroZW6lZQNjdrSSXUetxMKqNdu/TObccjln8bVtv72rmpGYViBAoVk3JLXbuEtTUA4y0s5CpopW7JsXK/8bLysoXGKsReT3ytXt8pe73Mg9fKz1e+T+cH40Dnb2xdSxniC0trAMZ7OLSiQk/3oqpslrgUw53Xzqt6POxY9U6jmKZoB633YwZyWNC7Cyv699Tc11wrxMftdRkl7JGroJbNsnLxHLx25IxujLyBCrFbLZQtVYNArSEXp5CvU+7pR6UKtXxIBWDdi9YbjMEw5bBHrkGqM4m9vatwrP8m9HQvwjMHMrqVclKM8MifL9M9Z9BEPEiUC3eQmnY5Qa1etN5gDEdpbLH2OBM42CM3gVYDohgRpoSo2ISqtVqUiTaZbCHUYmXDUqtPkNxiwjE4xTD0sJCbQGspOyUEjvXfVPFY3+ol+C8DI5hy0R6zRSxehyjMdma0w4qPF3LH/UAubZenD1lFDrX0PH0QgHGoRa9gjWHKYSE3gVYWi7zELU8RSzRLrgfDzYqwXojCTHMpNfQ2R7XscrIS8/jZHOJSA3J5e7fKGY0xJJobS78zIYAPcvmK/ZBMNlfKVIoRIZPNYevuoxWFYbVUhuYnBTa9cNiUIAehOpNTIIMPC7kJ9Ja4yhSxMFZ76om4XJ6vlWZnxrt30kt3qrf839zaoStGatW98vV37DtRuk/XurIJy+dkY/pQxc9rZvOWhd97WMhNoLfEXdG/py4a+Lu9AVnuwbrd/2TN8jZDYdEbzBCVTWsjwU0PZypEXEZvOhLnvvsDC7lJtJa4ZlPBZjVLaG6chtPZHBo0CouSiTguXJwIjbfmBGoNudxOMeyaP1vzuY3pQ9i5/6Slwq9aImmJuGR8kIuYEdytu49q/lxan3u93HcWcvdgIbeJmVFycSmGh25eUvogK/+I5GN+NrEG0tR5QOF4hi1/OuisHxjBuoGRqr7cd//9P9e8kbpmeVvpBtBAwPRpDRjLTyHRLOGDC/mKzW+pgdC3eokDP0ntmBFcWaw19zgerm6qxbnv/sBCbhO1+LkUI8xonFbaPFMuWbVCNdLgedVr1Bq+8CKLxAsI0FzF1EJ5vHddUdTtMDcRx+ZUh+ZE+nIvP0aE26+Z57t3akZwZSfFyjANo8QAxh1sCTkRfQGFYVefAHCNEGLICaPCRK0pYqqhmkF7tuhlh8jxZatNrZyg1pi3XvokoP6zuLV6kbNX1MIomWwO7b270Bgj5CdFVV/7Zw5kSjehSSHwzIGMY021akVXcIttbfcCVatDIzzLfWcqsOuRvwHgNgB/54AtoSUIKWKAvki30FgpHq1Xfq81RMLOBmStwlrLBqsyqwZwRtzf3nIjgEJYTKvo6+LkpcyWdQMj6Hv+MIgQyJixruAO1t6+lnPf/cGWkAsh3gQAMpuEzISWpePbVT3kFhrDG9PXBjqG70R4qb13VymmfuHihKnX6FX4+h0z1hVcmyvDoDg29YRnMXIiugfAPQDQ1tbm1WUjw5WXz8Bb76nH0L0iaj1QrCIPjnAiUh+EmDELbnQwFHIi+imAj6o89aAQwvS9WwixDcA2AOjq6opKKq6zNLaobiCNiiac+d1FHwyyRhi6Fq5Z3qaaG20WJz64kYkZc1OtwGAo5EKI670whAHwQAYLendpiIU3ueV24stB99jXLG/D5lQHuubPRs9TB5HX6znsIIm4hBnTp0UjZtz3QcW3Zqs4lW0sylsihPr9CAicfhgwzOSla6GXblhrBoqfImy0wWrFthUfn11KD1TGh99oWosZcG8l0bd6SbiESmNlqPTAzVZx6rWxkF9z066rIU1ohA55CLQhdtMPbwXwPwHMAbCLiEaEEN2OWFanaGUTNEkNuhWfyUQcP+1+vZTyppcbHZb8cisiqpeJMyqacPxs4eao9CC/ffsyzBh0dyURKhEHTIum2SpOvXYH8mukmM7+Dw+BNsRu1spzAJ5zyBYG2tkEAKoEngDcXQwXKM+x6YXDmsKvJpBmJgLp3QC8mihUC0vHt4PGc6oe5LqBEaRqTJePSzFsua3QfKu9d5fqMVHO5zJbxel3hk49wKGVAKKXTWA2P/ehm5dUCb9dar0ByLi5GWpmuv39Tx50pDqUgKr3f83yNjy+70TVsXcvj26GltkqTjvhQsYcLOQhwkq6WKoziaF3zlU1gDKaK+oGRjFtr8I8Toh4MhHH3t5VFY+lhzN47ciZqmNnNMZ0G3SFHbNVnGrHMc7CQh5RlKXhwKVQgFrYxY3WsVpVom7gxU1CTaTUGqDJnL84GekWrmarOJXHlWetzIxLPBrRAVjII4rWRtS6gRHEpeqZ20HJ8w4ayURcV6TMbOT5XY7vJmZXiVrHrejfg2wur78Bz/nqhrCQRxS9DSa7Y9KihqaINLZUhVGUmNnI480+beT3RsuR+M7tyyJ7E3QSFvKI4tUGk9vTfAD3K0blcxBQNUy7HLXiFzPvcxDK8YOK3vs3q1liETcJC3lE8WqDyYqQ1ir6Xm2S6gmuVvHL5z+TLA1iVqN8tquXHQHDMjezp3uRapWtFCM8dLO/wzfCBAt5RCnfYApK6pebcXi7KwMCdPufaO05vHbkDLbc1lESzZlxCURA9kJeswbA7TmWYZqbKdtT3hp4VrNUMVGLMYaEQ1NXrNDV1SWGhupuBoVv6GVWAAXvBwKe9R6xSi3902tBLT9cRqsHjlE4Bihs6KndTNVSGZ3A6+sx3kFEB4QQXcrH2SOvA5TpX1peo+y91zJMOCzEdEbGCWh7r3ZGmHk9x1LrvEFZmTHOw0IeQbTio2bGzylfD0RD1GVv1Gh1AqinDNoZYeb1HEut6xEKv1sOWUSP6oRiJtTIQpXJ5io8zPSw+e5xqc4k9vauwrH+m/Dt25chLsXcM9gEWnFus/HvcsFNdSax5bYOJBNx3T4oSq9W+bpkIl7qs2JET/eiqvfQzZ7kPd2LVH82uU2Blc8CEw44Rh4x3IiPKj388+MTnlXj1Zp6GCPClBCGGRta75dMIi5VtaGtJSPE6ywSrSZeQGWzLyZccIy8TnAjHqsMy5gJTzhFramHU0IYbkICwMrFc1SbXclkc3n0PHUQAEotgmvJCPF6rFpSJz876tWm9QgLecTwIh4rN+TSG5kmrwA2pg/pCqVbNBBhQe8uQ+/3xYPvVnyvtQIQgwAGgRSAVAxAMVIirwycEkanPHejOoIwVpuGJTfeD1jII4adTTkr7PrVu5oiXn49ta6AXiBnpsg9x9cNjCCp8sevDBFpefpa8XT5eCeE0cn8b/l4rda9Yas2Hf/GFUhNXUAKAJoAjAEYBPK7ZkDaeNpf4wIAC3nEMNuRzg7p4YzutKLy+Kubnl95frmZcv1yYQSATS8cdswWJ4TR7MQds8ivcfPG7oWXvDF9CJunLqg+pzkers5gIY8gTsdjlX+sFy5OaB6bTMRN5V87jdly/Vx+Eg88+ytccLBxWFyKYeXiOVjRv8eUoGmJn1v7G4A7N3YvKkjTwxns2HcCm51r3RNJWMgZXdT+WPVweqiAG/NFnRRxAFX9VvQETe39XD8wgqF3zmne9BLNkumbhBpubbQ6vYLQukYU6hjchvPIGV2M+m2Xk4hXd6tLdSbx6baZNV9/6fh2tI89UfoXRF47ckZT0JSovZ8CwI59J7By8ZyqfHMpRhgdm7BVF+AG6eGM5k3dyXBaGDdl/YCFnNHF7B9SXIqhb3V1t7qN6UPY+/a5qsdXfHw2EnHJtn1Oo1VkpFlu0dhiKSSidawASg24youOZjROq+qBo3WTcIL0cAYr+vdgQe8urOjfo3rDkFcVWjixXyDbwd64OTi0wuiiudyPS5gxfZrhcn/n/pOq59336/fx9pYbAVTGjJukhpoHX6g117Las9yoyOh//Pmnqn7OuRpFRWqCprdncDqbq4ppawlZJptzvNzebMxbb5XmxEaqWp2C3vAPhoWcMUArnVFZ7aiFVoOq8sflGG56OIP1AyO657MaM3cqvq5XDWkl5bOnexHWD4yoCvTcRNxSsZXTG4tmY956qzQnKkbV7JBvsGoppAwLOWOA3awHrW6DMarOzDazsaXlMeu1ujWDXsdHo/7YVt4jrWIqWfit7Ek4vbFoNkSktapQZiw5bQcB3IZXAxZyxhA7WQ93XjtPtbLzzmvnVT3m58aW3g2kuXGaqc6RZt+jzakOdM2frSr8RisSJU6+Z2argt0uOvO6W2QUYCFnXGVzqgNAIVY+KQRiRLjz2nmlx8vRix/72SPdjTx4LeG3mnc/0+SGsZnCHbMC7XbRmVfVyVGChZxxnc2pDlXhVqL2B0wA7l7ehq75sz1r1KVELQzkFlbz7s9fnDDc9DS7iWk1RORWnNqL6uSowW1smUCh5zmmhzPY9MJh1fYAtba7NYPWudHYAjzgfD63/B6Y9cyNWhTz6LfooNXGloWcCR16Yt/5jVd0+8Bo0Rgj5CeFavhGdyO17wPL1zKLXq90MzcXMzeE4yZa/TLBgfuRM+Hm4SRwcRRAsZUsUOiCN9UCdF7yirM1iLgUI/z3P/uUZjaJX+iFWTTTKovvkZk0Rh79Fh1sVXYS0VYiOkJEvyKi54go4ZRhDFNBUaCMHrea2ZBMxLH1zwpFPptTHfj27cuqxrn5Rfl4OQBosBCqN5PGKIrHMeHHrkf+KoANQogJIvomgA0Avm7fLIapDaubhcoYseom3qBT1llHbTrT1t1HC/24dTCbluhFZ0rGfWx55EKIV4QQck/TfQBa7ZvEMLWjNiRZq6dLMoR5yfJgbCPMrky8zMhh3MPJGPlaAANaTxLRPQDuAYC2tjYHL8swlZiZMWopL7mxRT20E+A+H2ZXJlotFJhwYSjkRPRTAB9VeepBIcRg8ZgHAUwA2KF1HiHENgDbgELWSk3WMkwN2M5LdiHF0DYGNxf5Z1tnUCkaxlUJU42hkAshrtd7noi+DOBzAD4r/MhlZOoDm16x11PsXcfEzSXVmdSc2SnD1ZLRwFZohYhuQGFz84+EEOpD9RjGCYLoFQeU8jx7Pc9qzfK2aN3c6hi7MfLvAZgO4FUqbJrsE0Lca9sqhmFqwmwb3ERcMtU2gQkHtoRcCLHQKUMYhrGPmfxxrWlOTHjhyk6GCTlmQykAD2aIKizkDBNirEwU4iZZ0YWHLzNMiLEyUYgn0kcXFnKGCTFWxJkn7EQXFnKGCTFa4qwsvOcJO9GGhZxhQkxP96KqVrtxKYa7l7dVdXHkDc7owpudDBNieCwaA7CQM0zoiVz7AcYyHFphGIYJOSzkDMMwIYeFnGEYJuSwkDMMw4QcFnKGYZiQQ37MgiCiMwDe8fzClVwG4Lc+26BHkO0Lsm0A22eHINsGsH3zhRBzlA/6IuRBgIiGhBBdftuhRZDtC7JtANtnhyDbBrB9WnBohWEYJuSwkDMMw4ScehbybX4bYECQ7QuybQDbZ4cg2wawfarUbYycYRgmKtSzR84wDBMJWMgZhmFCTl0LORFtJaIjRPQrInqOiBJ+21QOEX2BiA4T0RQRBSLliohuIKKjRPRvRNTrtz3lENF2InqPiN7w2xYlRDSPiF4jojeLv9Ov+W1TOUTURES/JKKDRfs2+W2TEiKKEdEwEb3oty1KiOg4ER0iohEiGvL6+nUt5ABeBbBUCPFJAP8XwAaf7VHyBoDbAPzcb0OAwh8SgO8D+FMAVwG4k4iu8teqCv4RwA1+G6HBBID7hRCfALAcwH0Be+/GAawSQnwKwDIANxDRcp9tUvI1AG/6bYQOK4UQyziP3GOEEK8IISaK3+4D0OqnPUqEEG8KIY76bUcZ1wD4NyHEr4UQFwH8GMAtPttUQgjxcwDn/LZDDSHEu0KI14tf/w4FQQpME3FRYLT4rVT8F5hMCCJqBXATgH/w25YgUtdCrmAtgJf9NiLgJAGcLPv+FAIkRmGBiNoBdALY768llRRDFyMA3gPwqhAiSPZ9B8B/AzDltyEaCACvENEBIrrH64tHfkIQEf0UwEdVnnpQCDFYPOZBFJa+O7y0rXhtQ/sChHKmLxAgry0MEFELgGcArBNCfOi3PeUIISYBLCvuFT1HREuFEL7vNxDR5wC8J4Q4QER/7Lc9GqwQQpwmossBvEpER4orRE+IvJALIa7Xe56IvgzgcwA+K3xIqjeyL2CcAjCv7PtWAKd9siV0EJGEgojvEEI867c9WgghskT0MxT2G3wXcgArAKwmohsBNAH4PSJ6XAixxme7SgghThf/f4+InkMhDOmZkNd1aIWIbgDwdQCrhRAX/LYnBPwLgCuJaAERNQK4A8DzPtsUCoiIADwK4E0hxCN+26OEiObIWVtEFAdwPYAj/lpVQAixQQjRKoRoR+EztydIIk5EM4joI/LXAP4EHt8A61rIAXwPwEdQWAqNENEP/DaoHCK6lYhOAbgOwC4i2u2nPcWN4b8EsBuFzbonhRCH/bSpHCLaCeCfASwiolNE9BW/bSpjBYAvAlhV/KyNFD3MoHAFgNeI6Fco3LBfFUIELs0voPwBgF8Q0UEAvwSwSwjxEy8N4BJ9hmGYkFPvHjnDMEzoYSFnGIYJOSzkDMMwIYeFnGEYJuSwkDMMw4QcFnKGYZiQw0LOMAwTcv4/NN3DARPfosoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing outliers with NaN .....................................\n",
      "Replacing NaN with averages. .....................................\n",
      "Normalizing scale between 0 and 1..................................\n",
      "Preparing Kaggle test dataset.......................................\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 5370 is out of bounds for axis 0 with size 4564",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8c302c0b81cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mXKaggleTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mXKaggleTest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 5370 is out of bounds for axis 0 with size 4564"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print('Filling np arrays with dataframes sources.......................')\n",
    "X = input_dataset.iloc[:,1:].values\n",
    "y = class_dataset.iloc[:,:].values\n",
    "X_test_index = test_dataset.iloc[:,:].values\n",
    "print('X',X.shape)\n",
    "print('y',y.shape)\n",
    "print('X_test_index',X_test_index.shape)\n",
    "\n",
    "print('Removing features with no variance....................................')\n",
    "variance_mask = VarianceThreshold().fit(X).get_support()\n",
    "X = X[:,variance_mask]\n",
    "\n",
    "print('Replacing outliers with NaN .....................................')\n",
    "df = pd.DataFrame(data=X)\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "mask = (df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))\n",
    "df[mask] = np.nan\n",
    "print('Replacing NaN with averages. .....................................')\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.fillna(df.mean())\n",
    "X = df.iloc[:,:].values\n",
    "\n",
    "print('Normalizing scale between 0 and 1..................................')\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Preparing Kaggle test dataset.......................................')\n",
    "XKaggleTest = np.zeros((X_test_index.shape[0], X.shape[1]))\n",
    "for i in range(X_test_index.shape[0]):\n",
    "    XKaggleTest[i]= X[X_test_index[i][0]]\n",
    "\n",
    "\n",
    "print('Copying a subset of X and y with classes.............................')\n",
    "X_tmp = np.zeros((y.shape[0], X.shape[1]))\n",
    "y_tmp = np.zeros(y.shape[0])\n",
    "\n",
    "for i in range(y.shape[0]):\n",
    "    X_tmp[i] = X[y[i][0]]\n",
    "    y_tmp[i]= y[i][1]\n",
    "\n",
    "X = X_tmp\n",
    "y = y_tmp\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n",
    "\n",
    "'''\n",
    "print('Removing outliers samples...............................................')\n",
    "print(X_train.shape)\n",
    "xdf = pd.DataFrame(data=X_train)\n",
    "z = np.abs(stats.zscore(xdf))\n",
    "X_train = X_train[(z < 30).all(axis=1)]\n",
    "y_train = y_train[(z < 30).all(axis=1)]\n",
    "print(X_train.shape)\n",
    "#-------------------------------------------------------\n",
    "xdf = pd.DataFrame(data=X)\n",
    "z = np.abs(stats.zscore(xdf))\n",
    "X = X[(z < 5).all(axis=1)]\n",
    "y = y[(z < 5).all(axis=1)]\n",
    "'''\n",
    "\n",
    "print('Balancing number of classes...............................................')\n",
    "xdf = pd.DataFrame(data=X_train)\n",
    "ydf = pd.DataFrame(data=y_train, columns=['class'])\n",
    "zdf = pd.concat([xdf,ydf], axis=1)\n",
    "\n",
    "xdf_z = zdf[zdf['class']==0]\n",
    "xdf_o = zdf[zdf['class']==1]\n",
    "xdf_m = zdf[zdf['class']==-1]\n",
    "\n",
    "xdf_z = resample(xdf_z, \n",
    "                 replace=True,     # sample with replacement\n",
    "                 n_samples=xdf_m.shape[0],    # to match majority class\n",
    "                 random_state=123) # reproducible results\n",
    "\n",
    "xdf_o = resample(xdf_o, \n",
    "                 replace=True,     # sample with replacement\n",
    "                 n_samples=xdf_m.shape[0],    # to match majority class\n",
    "                 random_state=123) # reproducible results\n",
    "\n",
    "totaldf = pd.concat([xdf_z,xdf_o,xdf_m])\n",
    "y_train = totaldf['class']\n",
    "X_train = totaldf.drop('class', axis=1).iloc[:,:].values\n",
    "\n",
    "#-------------------------------------------------------\n",
    "\n",
    "\n",
    "xdf = pd.DataFrame(data=X)\n",
    "ydf = pd.DataFrame(data=y, columns=['class'])\n",
    "zdf = pd.concat([xdf,ydf], axis=1)\n",
    "\n",
    "xdf_z = zdf[zdf['class']==0]\n",
    "xdf_o = zdf[zdf['class']==1]\n",
    "xdf_m = zdf[zdf['class']==-1]\n",
    "\n",
    "xdf_z = resample(xdf_z, \n",
    "                 replace=True,     # sample with replacement\n",
    "                 n_samples=xdf_m.shape[0],    # to match majority class\n",
    "                 random_state=123) # reproducible results\n",
    "\n",
    "xdf_o = resample(xdf_o, \n",
    "                 replace=True,     # sample with replacement\n",
    "                 n_samples=xdf_m.shape[0],    # to match majority class\n",
    "                 random_state=123) # reproducible results\n",
    "\n",
    "totaldf = pd.concat([xdf_z,xdf_o,xdf_m])\n",
    "y = totaldf['class']\n",
    "X = totaldf.drop('class', axis=1).iloc[:,:].values\n",
    "\n",
    "print('\\nDimensao de X_train: ', X_train.shape)\n",
    "print('\\nDimensao de X: ', X.shape)\n",
    "\n",
    "print('\\nDimensao de y_train: ', y_train.shape)\n",
    "print('\\nDimensao de y: ', y.shape)\n",
    "\n",
    "print('\\nClasses do problema: ', np.unique(y_train))\n",
    "print('\\nClasses do problema: ', np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Experimento\n",
    "\n",
    "Nesta seção, o experimento deve ser conduzido, utilizando os protocolos experimentais ensinados no curso e executando os métodos inteligentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.5777305968388771\n",
      "NB Accuracy: 0.564963503649635\n",
      "NB AUC: 0.727093677756736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.94      0.57      0.71      1212\n",
      "         0.0       0.12      0.66      0.20        76\n",
      "         1.0       0.16      0.45      0.24        82\n",
      "\n",
      "    accuracy                           0.56      1370\n",
      "   macro avg       0.41      0.56      0.38      1370\n",
      "weighted avg       0.85      0.56      0.65      1370\n",
      "\n",
      "Train: 0.999174333569238\n",
      "NN Accuracy: 0.8394160583941606\n",
      "NN AUC: 0.9998670759245373\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.91      0.91      0.91      1212\n",
      "         0.0       0.27      0.28      0.27        76\n",
      "         1.0       0.28      0.27      0.27        82\n",
      "\n",
      "    accuracy                           0.84      1370\n",
      "   macro avg       0.49      0.49      0.49      1370\n",
      "weighted avg       0.84      0.84      0.84      1370\n",
      "\n",
      "Train: 0.607454588346308\n",
      "RR Accuracy: 0.7700729927007299\n",
      "RR AUC: 0.7585061699366342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.93      0.82      0.87      1212\n",
      "         0.0       0.20      0.58      0.29        76\n",
      "         1.0       0.26      0.26      0.26        82\n",
      "\n",
      "    accuracy                           0.77      1370\n",
      "   macro avg       0.46      0.55      0.47      1370\n",
      "weighted avg       0.85      0.77      0.80      1370\n",
      "\n",
      "Train: 0.7999528190610993\n",
      "LR Accuracy: 0.6693430656934306\n",
      "LR AUC: 0.9107936026272716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.93      0.70      0.80      1212\n",
      "         0.0       0.15      0.47      0.23        76\n",
      "         1.0       0.14      0.39      0.21        82\n",
      "\n",
      "    accuracy                           0.67      1370\n",
      "   macro avg       0.41      0.52      0.41      1370\n",
      "weighted avg       0.84      0.67      0.73      1370\n",
      "\n",
      "Train: 0.953172918141071\n",
      "KNN Accuracy: 0.7562043795620438\n",
      "KNN AUC: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.92      0.81      0.86      1212\n",
      "         0.0       0.13      0.26      0.18        76\n",
      "         1.0       0.21      0.40      0.28        82\n",
      "\n",
      "    accuracy                           0.76      1370\n",
      "   macro avg       0.42      0.49      0.44      1370\n",
      "weighted avg       0.84      0.76      0.79      1370\n",
      "\n",
      "Train: 0.9610757254069356\n",
      "SVM Accuracy: 0.8204379562043795\n",
      "SVM AUC: 0.9932838478006979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.93      0.88      0.90      1212\n",
      "         0.0       0.24      0.38      0.30        76\n",
      "         1.0       0.29      0.35      0.32        82\n",
      "\n",
      "    accuracy                           0.82      1370\n",
      "   macro avg       0.49      0.54      0.51      1370\n",
      "weighted avg       0.85      0.82      0.83      1370\n",
      "\n",
      "Printing model to submission.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "model = GaussianNB()\n",
    "y_pred = model.fit(X_train, y_train).predict(X_train)\n",
    "print(\"Train:\",metrics.accuracy_score(y_train, y_pred))\n",
    "y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "print(\"NB Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "y_proba = model.fit(X, y).predict_proba(X_test)\n",
    "print(\"NB AUC:\",metrics.roc_auc_score(y_test, y_proba,multi_class='ovo'))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "model = MLPClassifier( alpha=1e-5, hidden_layer_sizes=(300,), random_state=1, max_iter=5000)\n",
    "y_pred = model.fit(X_train, y_train).predict(X_train)\n",
    "print(\"Train:\",metrics.accuracy_score(y_train, y_pred))\n",
    "y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "print(\"NN Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "y_proba = model.fit(X, y).predict_proba(X_test)\n",
    "print(\"NN AUC:\",metrics.roc_auc_score(y_test, y_proba,multi_class='ovo'))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "model = RandomForestClassifier(max_depth=2, random_state=1)\n",
    "y_pred = model.fit(X_train, y_train).predict(X_train)\n",
    "print(\"Train:\",metrics.accuracy_score(y_train, y_pred))\n",
    "y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "print(\"RR Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "y_proba = model.fit(X, y).predict_proba(X_test)\n",
    "print(\"RR AUC:\",metrics.roc_auc_score(y_test, y_proba,multi_class='ovo'))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Printing model to submission.csv')\n",
    "y_pred_submission = model.fit(X, y).predict_proba(XKaggleTest)[:,2:3]\n",
    "\n",
    "if True:\n",
    "    model = LogisticRegression(random_state=1, max_iter=15000)\n",
    "    y_pred = model.fit(X_train, y_train).predict(X_train)\n",
    "    print(\"Train:\",metrics.accuracy_score(y_train, y_pred))\n",
    "    y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "    print(\"LR Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    y_proba = model.fit(X, y).predict_proba(X_test)\n",
    "    print(\"LR AUC:\",metrics.roc_auc_score(y_test, y_proba,multi_class='ovo'))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    model = KNeighborsClassifier()\n",
    "    y_pred = model.fit(X_train, y_train).predict(X_train)\n",
    "    print(\"Train:\",metrics.accuracy_score(y_train, y_pred))\n",
    "    y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "    print(\"KNN Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    y_proba = model.fit(X, y).predict_proba(X_test)\n",
    "    print(\"KNN AUC:\",metrics.roc_auc_score(y_test, y_proba,multi_class='ovo'))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    model = svm.SVC(decision_function_shape='ovo', probability=True,random_state=1)\n",
    "    y_pred = model.fit(X_train, y_train).predict(X_train)\n",
    "    print(\"Train:\",metrics.accuracy_score(y_train, y_pred))\n",
    "    y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "    print(\"SVM Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    y_proba = model.fit(X, y).predict_proba(X_test)\n",
    "    print(\"SVM AUC:\",metrics.roc_auc_score(y_test, y_proba,multi_class='ovo'))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    \n",
    "\n",
    "result = np.zeros((X_test_index.shape[0],2))\n",
    "for i in range(X_test_index.shape[0]):\n",
    "    result[i][0] = X_test_index[i][0]\n",
    "    result[i][1] = y_pred_submission[i]\n",
    "\n",
    "resultdf = pd.DataFrame(data=result, columns=[\"Id\", \"Predicted\"])\n",
    "\n",
    "resultdf['Id'] = resultdf['Id'].astype(int)\n",
    "resultdf['Predicted'] = resultdf['Predicted'].round(decimals=5)\n",
    "\n",
    "resultdf.to_csv('submission.csv', index=False, float_format='%.5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Análise dos Resultados\n",
    "\n",
    "Nesta seção, os resultados devem ser exibidos e comparados, através de tabelas e gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
