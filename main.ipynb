{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"figs/LogoUFSCar.jpg\" alt=\"Logo UFScar\" width=\"110\" align=\"left\"/>  <br/> <center>Universidade Federal de São Carlos (UFSCar)<br/><font size=\"4\"> Departamento de Computação, campus Sorocaba</center></font>\n",
    "</p>\n",
    "\n",
    "<font size=\"4\"><center><b>Disciplina: Aprendizado de Máquina</b></center></font>\n",
    "  \n",
    "<font size=\"3\"><center>Prof. Dr. Tiago A. Almeida</center></font>\n",
    "\n",
    "## <center>Projeto Final</center>\n",
    "\n",
    "**Aluno**: Eduardo Garcia do Nascimento\n",
    "\n",
    "**RA/CPF**: 22008732800\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Análise exploratória\n",
    "\n",
    "Nesta seção, deve ser feita a leitura da base de dados e todas as análises necessárias para entendê-la melhor, tais como:\n",
    "* Significado de cada atributo\n",
    "* Medidas descritivas\n",
    "* Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>D0000</th>\n",
       "      <th>D0001</th>\n",
       "      <th>D0002</th>\n",
       "      <th>D0003</th>\n",
       "      <th>D0004</th>\n",
       "      <th>D0005</th>\n",
       "      <th>D0006</th>\n",
       "      <th>D0007</th>\n",
       "      <th>D0008</th>\n",
       "      <th>...</th>\n",
       "      <th>D0138</th>\n",
       "      <th>D0139</th>\n",
       "      <th>D0140</th>\n",
       "      <th>D0141</th>\n",
       "      <th>D0142</th>\n",
       "      <th>D0143</th>\n",
       "      <th>D0144</th>\n",
       "      <th>D0145</th>\n",
       "      <th>D0146</th>\n",
       "      <th>D0147</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.336472</td>\n",
       "      <td>0.336472</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2.180207</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>-16.015176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447179</td>\n",
       "      <td>-14.656926</td>\n",
       "      <td>0.018882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.323004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.867641</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>-16.552813</td>\n",
       "      <td>1.781575</td>\n",
       "      <td>1.377964</td>\n",
       "      <td>-16.016694</td>\n",
       "      <td>0.025232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.266722</td>\n",
       "      <td>0.266722</td>\n",
       "      <td>2.928838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2.627386</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-16.548139</td>\n",
       "      <td>0.344645</td>\n",
       "      <td>0.108658</td>\n",
       "      <td>-15.307439</td>\n",
       "      <td>-0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.871201</td>\n",
       "      <td>3.784190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.737670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>1.637311</td>\n",
       "      <td>2.216004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.216561</td>\n",
       "      <td>0.829762</td>\n",
       "      <td>-14.697490</td>\n",
       "      <td>0.303174</td>\n",
       "      <td>0.401714</td>\n",
       "      <td>-14.083293</td>\n",
       "      <td>0.005164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>-2.175233</td>\n",
       "      <td>-2.175233</td>\n",
       "      <td>7.036531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.135548</td>\n",
       "      <td>0.554348</td>\n",
       "      <td>-9.595501</td>\n",
       "      <td>0.589175</td>\n",
       "      <td>0.100116</td>\n",
       "      <td>-13.572599</td>\n",
       "      <td>-0.000632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7.160069</td>\n",
       "      <td>6.442540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5.456945</td>\n",
       "      <td>3.897234</td>\n",
       "      <td>6.442540</td>\n",
       "      <td>...</td>\n",
       "      <td>3.914</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>5.476159</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>-12.069193</td>\n",
       "      <td>1.505100</td>\n",
       "      <td>0.357536</td>\n",
       "      <td>-10.992013</td>\n",
       "      <td>-0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6.877296</td>\n",
       "      <td>6.885510</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>3.942518</td>\n",
       "      <td>3.953152</td>\n",
       "      <td>5.791997</td>\n",
       "      <td>...</td>\n",
       "      <td>2.440</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>5.852683</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>-12.741077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081810</td>\n",
       "      <td>-11.460218</td>\n",
       "      <td>0.000516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>6.844815</td>\n",
       "      <td>6.844815</td>\n",
       "      <td>3.970292</td>\n",
       "      <td>3.970292</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>3.473438</td>\n",
       "      <td>3.473438</td>\n",
       "      <td>4.530772</td>\n",
       "      <td>...</td>\n",
       "      <td>1.946</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>5.818093</td>\n",
       "      <td>0.064151</td>\n",
       "      <td>-11.983040</td>\n",
       "      <td>1.424396</td>\n",
       "      <td>1.454859</td>\n",
       "      <td>-12.039741</td>\n",
       "      <td>-0.053146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.640779</td>\n",
       "      <td>-0.640779</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.368022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-17.207213</td>\n",
       "      <td>0.434202</td>\n",
       "      <td>1.788514</td>\n",
       "      <td>-17.173907</td>\n",
       "      <td>-0.424863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>4.043051</td>\n",
       "      <td>4.043051</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.429068</td>\n",
       "      <td>0.429068</td>\n",
       "      <td>3.214868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.436594</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>-15.812102</td>\n",
       "      <td>0.957110</td>\n",
       "      <td>0.443102</td>\n",
       "      <td>-14.505732</td>\n",
       "      <td>0.004381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id     D0000     D0001     D0002     D0003     D0004     D0005     D0006  \\\n",
       "0   0  2.564949  2.564949  2.079442  2.079442  1.000000  1.000000  0.336472   \n",
       "1   1  2.833213  2.197225  2.197225  2.197225  0.333333  1.000000 -0.323004   \n",
       "2   2  3.091042  3.091042  2.833213  2.833213  0.941176  0.941176  0.266722   \n",
       "3   3  3.871201  3.784190  0.000000  3.737670  0.000000  0.976190  1.637311   \n",
       "4   4  3.688879  3.688879  3.135494  3.135494  0.652174  0.652174 -2.175233   \n",
       "5   5  7.160069  6.442540  0.000000  3.178054  0.000000  0.666667  5.456945   \n",
       "6   6  6.877296  6.885510  2.079442  3.178054  1.000000  0.880000  3.942518   \n",
       "7   7  6.844815  6.844815  3.970292  3.970292  0.075472  0.075472  3.473438   \n",
       "8   8  1.609438  1.609438  0.693147  0.693147  0.000000  0.000000 -0.640779   \n",
       "9   9  4.043051  4.043051  2.197225  2.197225  1.000000  1.000000  0.429068   \n",
       "\n",
       "      D0007     D0008  ...  D0138  D0139    D0140     D0141     D0142  \\\n",
       "0  0.336472  2.197225  ...  0.024  0.040  0.00001  2.180207  0.850000   \n",
       "1  0.000000  2.197225  ...  0.020  0.058  0.00001  1.867641  0.850000   \n",
       "2  0.266722  2.928838  ...  0.046  0.028  0.00001  2.627386  0.800000   \n",
       "3  2.216004  0.000000  ...  0.226  0.030  0.00001  3.216561  0.829762   \n",
       "4 -2.175233  7.036531  ...  0.084  0.050  0.00001  3.135548  0.554348   \n",
       "5  3.897234  6.442540  ...  3.914  0.038  0.00001  5.476159  0.566667   \n",
       "6  3.953152  5.791997  ...  2.440  0.034  0.00001  5.852683  0.748000   \n",
       "7  3.473438  4.530772  ...  1.946  0.046  0.00001  5.818093  0.064151   \n",
       "8 -0.640779  0.405465  ...  0.054  0.056  0.00001  1.368022  0.000000   \n",
       "9  0.429068  3.214868  ...  0.090  0.034  0.00001  3.436594  0.850000   \n",
       "\n",
       "       D0143     D0144     D0145      D0146     D0147  \n",
       "0 -16.015176  0.000000  0.447179 -14.656926  0.018882  \n",
       "1 -16.552813  1.781575  1.377964 -16.016694  0.025232  \n",
       "2 -16.548139  0.344645  0.108658 -15.307439 -0.000148  \n",
       "3 -14.697490  0.303174  0.401714 -14.083293  0.005164  \n",
       "4  -9.595501  0.589175  0.100116 -13.572599 -0.000632  \n",
       "5 -12.069193  1.505100  0.357536 -10.992013 -0.146300  \n",
       "6 -12.741077  0.000000  0.081810 -11.460218  0.000516  \n",
       "7 -11.983040  1.424396  1.454859 -12.039741 -0.053146  \n",
       "8 -17.207213  0.434202  1.788514 -17.173907 -0.424863  \n",
       "9 -15.812102  0.957110  0.443102 -14.505732  0.004381  \n",
       "\n",
       "[10 rows x 149 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Caminho dos arquivos\n",
    "FILES_DIRECTORY = \"data\"\n",
    "\n",
    "import numpy as np  # importa a biblioteca usada para trabalhar com vetores e matrizes\n",
    "import pandas as pd # importa a biblioteca usada para trabalhar com dataframes (dados em formato de tabela) e análise de dados\n",
    "import os # importa a biblioteca para tarefas relacionadas ao sistema operacional\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "       \n",
    "            # importa o arquivo e guarda em um dataframe do Pandas\n",
    "            set1_dataset  = pd.read_csv(os.path.join(FILES_DIRECTORY, 'set1.csv'), sep=',', low_memory=False)\n",
    "            set2_dataset  = pd.read_csv(os.path.join(FILES_DIRECTORY, 'set2.csv'), sep=',', low_memory=False) \n",
    "            set3_dataset  = pd.read_csv(os.path.join(FILES_DIRECTORY, 'set3.csv'), sep=',', low_memory=False) \n",
    "\n",
    "            frames = [ set3_dataset ]\n",
    "            input_dataset = pd.concat(frames, axis=1)\n",
    "            display(input_dataset.head(10))\n",
    "            \n",
    "            class_dataset = pd.read_csv(os.path.join(FILES_DIRECTORY, 'train.csv'), sep=',', skiprows=range(0, 1), index_col=None, header=None)\n",
    "            test_dataset  = pd.read_csv(os.path.join(FILES_DIRECTORY, 'test.csv'), sep=',', skiprows=range(0, 1), index_col=None, header=None)\n",
    "\n",
    "            print('Dados carregados com sucesso!')\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Pré-processamento\n",
    "\n",
    "Nesta seção, as funções da etapa de pré-processamento dos dados devem ser implementadas e aplicadas (se necessário)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling np arrays with dataframes sources.......................\n",
      "X (60842, 148)\n",
      "y (4564, 2)\n",
      "X_test_index (401, 1)\n",
      "Removing features with no variance....................................\n",
      "Semi supervising algorithm............................................\n",
      "(60842,)\n",
      "(60842,)\n",
      "(60842, 147)\n",
      "(30421,)\n",
      "(30421, 147)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/en89912/anaconda3/lib/python3.8/site-packages/sklearn/semi_supervised/_label_propagation.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4564, 2)\n",
      "Replacing outliers with NaN .....................................\n",
      "Replacing NaN with averages. .....................................\n",
      "Normalizing scale between 0 and 1..................................\n",
      "Preparing Kaggle test dataset.......................................\n",
      "Copying a subset of X and y with classes.............................\n",
      "Balancing number of classes ...............................................\n",
      "\n",
      "Dimensao de X_train:  (29430, 147)\n",
      "\n",
      "Dimensao de X:  (12114, 147)\n",
      "\n",
      "Dimensao de y_train:  (29430,)\n",
      "\n",
      "Dimensao de y:  (12114,)\n",
      "\n",
      "Classes do problema:  [-1.  0.  1.]\n",
      "\n",
      "Classes do problema:  [-1.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "\n",
    "print('Filling np arrays with dataframes sources.......................')\n",
    "X = input_dataset.iloc[:,1:].values\n",
    "y = class_dataset.iloc[:,:].values\n",
    "X_test_index = test_dataset.iloc[:,:].values\n",
    "print('X',X.shape)\n",
    "print('y',y.shape)\n",
    "print('X_test_index',X_test_index.shape)\n",
    "\n",
    "print('Removing features with no variance....................................')\n",
    "variance_mask = VarianceThreshold().fit(X).get_support()\n",
    "X = X[:,variance_mask]\n",
    "\n",
    "df = pd.DataFrame(data=X)\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.fillna(df.mean())\n",
    "X = df.iloc[:,:].values\n",
    "\n",
    "print('Semi supervising algorithm............................................')\n",
    "y_full = np.full(X.shape[0], fill_value=np.inf)\n",
    "print(y_full.shape)\n",
    "\n",
    "for i in range(y.shape[0]):\n",
    "    y_full[y[i][0]]= y[i][1]\n",
    "\n",
    "y_full = np.where(y_full==-1, 2, y_full)\n",
    "y_full = np.where(y_full==np.inf, -1, y_full)\n",
    "print(y_full.shape)\n",
    "print(X.shape)\n",
    "X_full, X_test, y_full, y_test = train_test_split(X, y_full, test_size=0.5, random_state=0, stratify=y_full)\n",
    "print(y_full.shape)\n",
    "print(X_full.shape)\n",
    "label_prop_model = LabelSpreading()\n",
    "y_full = label_prop_model.fit(X_full, y_full).predict(X_full)\n",
    "y_full = np.where(y_full==2, -1, y_full)\n",
    "print(y.shape)\n",
    "\n",
    "print('Replacing outliers with NaN .....................................')\n",
    "df = pd.DataFrame(data=X)\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "mask = (df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))\n",
    "df[mask] = np.nan\n",
    "print('Replacing NaN with averages. .....................................')\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.fillna(df.mean())\n",
    "X = df.iloc[:,:].values\n",
    "\n",
    "print('Normalizing scale between 0 and 1..................................')\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "print('Preparing Kaggle test dataset.......................................')\n",
    "XKaggleTest = np.zeros((X_test_index.shape[0], X.shape[1]))\n",
    "for i in range(X_test_index.shape[0]):\n",
    "    XKaggleTest[i]= X[X_test_index[i][0]]\n",
    "\n",
    "\n",
    "print('Copying a subset of X and y with classes.............................')\n",
    "X_tmp = np.zeros((y.shape[0], X.shape[1]))\n",
    "y_tmp = np.zeros(y.shape[0])\n",
    "\n",
    "for i in range(y.shape[0]):\n",
    "    X_tmp[i] = X[y[i][0]]\n",
    "    y_tmp[i]= y[i][1]\n",
    "\n",
    "X = X_tmp\n",
    "y = y_tmp\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.3, random_state=0, stratify=y_full)\n",
    "\n",
    "'''\n",
    "print('Removing outliers samples...............................................')\n",
    "print(X_train.shape)\n",
    "xdf = pd.DataFrame(data=X_train)\n",
    "z = np.abs(stats.zscore(xdf))\n",
    "X_train = X_train[(z < 30).all(axis=1)]\n",
    "y_train = y_train[(z < 30).all(axis=1)]\n",
    "print(X_train.shape)\n",
    "#-------------------------------------------------------\n",
    "xdf = pd.DataFrame(data=X)\n",
    "z = np.abs(stats.zscore(xdf))\n",
    "X = X[(z < 5).all(axis=1)]\n",
    "y = y[(z < 5).all(axis=1)]\n",
    "'''\n",
    "\n",
    "print('Balancing number of classes ...............................................')\n",
    "xdf = pd.DataFrame(data=X_train)\n",
    "ydf = pd.DataFrame(data=y_train, columns=['class'])\n",
    "zdf = pd.concat([xdf,ydf], axis=1)\n",
    "\n",
    "xdf_z = zdf[zdf['class']==0]\n",
    "xdf_o = zdf[zdf['class']==1]\n",
    "xdf_m = zdf[zdf['class']==-1]\n",
    "\n",
    "xdf_z = resample(xdf_z, \n",
    "                 replace=True,     # sample with replacement\n",
    "                 n_samples=xdf_m.shape[0],    # to match majority class\n",
    "                 random_state=123) # reproducible results\n",
    "\n",
    "xdf_o = resample(xdf_o, \n",
    "                 replace=True,     # sample with replacement\n",
    "                 n_samples=xdf_m.shape[0],    # to match majority class\n",
    "                 random_state=123) # reproducible results\n",
    "\n",
    "totaldf = pd.concat([xdf_z,xdf_o,xdf_m])\n",
    "y_train = totaldf['class']\n",
    "X_train = totaldf.drop('class', axis=1).iloc[:,:].values\n",
    "\n",
    "#-------------------------------------------------------\n",
    "\n",
    "\n",
    "xdf = pd.DataFrame(data=X)\n",
    "ydf = pd.DataFrame(data=y, columns=['class'])\n",
    "zdf = pd.concat([xdf,ydf], axis=1)\n",
    "\n",
    "xdf_z = zdf[zdf['class']==0]\n",
    "xdf_o = zdf[zdf['class']==1]\n",
    "xdf_m = zdf[zdf['class']==-1]\n",
    "\n",
    "xdf_z = resample(xdf_z, \n",
    "                 replace=True,     # sample with replacement\n",
    "                 n_samples=xdf_m.shape[0],    # to match majority class\n",
    "                 random_state=123) # reproducible results\n",
    "\n",
    "xdf_o = resample(xdf_o, \n",
    "                 replace=True,     # sample with replacement\n",
    "                 n_samples=xdf_m.shape[0],    # to match majority class\n",
    "                 random_state=123) # reproducible results\n",
    "\n",
    "totaldf = pd.concat([xdf_z,xdf_o,xdf_m])\n",
    "y = totaldf['class']\n",
    "X = totaldf.drop('class', axis=1).iloc[:,:].values\n",
    "\n",
    "print('\\nDimensao de X_train: ', X_train.shape)\n",
    "print('\\nDimensao de X: ', X.shape)\n",
    "\n",
    "print('\\nDimensao de y_train: ', y_train.shape)\n",
    "print('\\nDimensao de y: ', y.shape)\n",
    "\n",
    "print('\\nClasses do problema: ', np.unique(y_train))\n",
    "print('\\nClasses do problema: ', np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Experimento\n",
    "\n",
    "Nesta seção, o experimento deve ser conduzido, utilizando os protocolos experimentais ensinados no curso e executando os métodos inteligentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.43013931362555213\n",
      "NB Accuracy: 0.18998575654651034\n",
      "NB AUC: 0.49989012639353597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.59      0.05      0.09      4205\n",
      "         0.0       0.91      0.29      0.44      4743\n",
      "         1.0       0.02      0.94      0.05       179\n",
      "\n",
      "    accuracy                           0.19      9127\n",
      "   macro avg       0.51      0.43      0.19      9127\n",
      "weighted avg       0.74      0.19      0.27      9127\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/en89912/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.6878355419639823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/en89912/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Accuracy: 0.6802892516708666\n",
      "LR AUC: 0.5006990774118706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.79      0.68      0.73      4205\n",
      "         0.0       0.87      0.68      0.77      4743\n",
      "         1.0       0.07      0.69      0.13       179\n",
      "\n",
      "    accuracy                           0.68      9127\n",
      "   macro avg       0.58      0.68      0.54      9127\n",
      "weighted avg       0.82      0.68      0.74      9127\n",
      "\n",
      "Train: 0.6206252123683317\n",
      "RR Accuracy: 0.6034841678536211\n",
      "RR AUC: 0.3971064026729643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.66      0.73      0.70      4205\n",
      "         0.0       0.90      0.49      0.63      4743\n",
      "         1.0       0.06      0.66      0.11       179\n",
      "\n",
      "    accuracy                           0.60      9127\n",
      "   macro avg       0.54      0.63      0.48      9127\n",
      "weighted avg       0.77      0.60      0.65      9127\n",
      "\n",
      "Printing model to submission.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "model = GaussianNB()\n",
    "y_pred = model.fit(X_train, y_train).predict(X_train)\n",
    "print(\"Train:\",metrics.accuracy_score(y_train, y_pred))\n",
    "y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "print(\"NB Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "y_proba = model.fit(X, y).predict_proba(X_test)\n",
    "print(\"NB AUC:\",metrics.roc_auc_score(y_test, y_proba,multi_class='ovo'))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "model = LogisticRegression(random_state=1, max_iter=15000)\n",
    "y_pred = model.fit(X_train, y_train).predict(X_train)\n",
    "print(\"Train:\",metrics.accuracy_score(y_train, y_pred))\n",
    "y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "print(\"LR Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "y_proba = model.fit(X, y).predict_proba(X_test)\n",
    "print(\"LR AUC:\",metrics.roc_auc_score(y_test, y_proba,multi_class='ovo'))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "model = RandomForestClassifier(max_depth=2, random_state=1)\n",
    "y_pred = model.fit(X_train, y_train).predict(X_train)\n",
    "print(\"Train:\",metrics.accuracy_score(y_train, y_pred))\n",
    "y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "print(\"RR Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "y_proba = model.fit(X, y).predict_proba(X_test)\n",
    "print(\"RR AUC:\",metrics.roc_auc_score(y_test, y_proba,multi_class='ovo'))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Printing model to submission.csv')\n",
    "y_pred_submission = model.fit(X, y).predict_proba(XKaggleTest)[:,2:3]\n",
    "\n",
    "if False:\n",
    "    model = MLPClassifier( alpha=1e-5, hidden_layer_sizes=(300,), random_state=1, max_iter=5000)\n",
    "    y_pred = model.fit(X_train, y_train).predict(X_train)\n",
    "    print(\"Train:\",metrics.accuracy_score(y_train, y_pred))\n",
    "    y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "    print(\"NN Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    y_proba = model.fit(X, y).predict_proba(X_test)\n",
    "    print(\"NN AUC:\",metrics.roc_auc_score(y_test, y_proba,multi_class='ovo'))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    model = KNeighborsClassifier()\n",
    "    y_pred = model.fit(X_train, y_train).predict(X_train)\n",
    "    print(\"Train:\",metrics.accuracy_score(y_train, y_pred))\n",
    "    y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "    print(\"KNN Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    y_proba = model.fit(X, y).predict_proba(X_test)\n",
    "    print(\"KNN AUC:\",metrics.roc_auc_score(y_test, y_proba,multi_class='ovo'))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    model = svm.SVC(decision_function_shape='ovo', probability=True,random_state=1)\n",
    "    y_pred = model.fit(X_train, y_train).predict(X_train)\n",
    "    print(\"Train:\",metrics.accuracy_score(y_train, y_pred))\n",
    "    y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "    print(\"SVM Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    y_proba = model.fit(X, y).predict_proba(X_test)\n",
    "    print(\"SVM AUC:\",metrics.roc_auc_score(y_test, y_proba,multi_class='ovo'))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    \n",
    "\n",
    "result = np.zeros((X_test_index.shape[0],2))\n",
    "for i in range(X_test_index.shape[0]):\n",
    "    result[i][0] = X_test_index[i][0]\n",
    "    result[i][1] = y_pred_submission[i]\n",
    "\n",
    "resultdf = pd.DataFrame(data=result, columns=[\"Id\", \"Predicted\"])\n",
    "\n",
    "resultdf['Id'] = resultdf['Id'].astype(int)\n",
    "resultdf['Predicted'] = resultdf['Predicted'].round(decimals=5)\n",
    "\n",
    "resultdf.to_csv('submission.csv', index=False, float_format='%.5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Análise dos Resultados\n",
    "\n",
    "Nesta seção, os resultados devem ser exibidos e comparados, através de tabelas e gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
